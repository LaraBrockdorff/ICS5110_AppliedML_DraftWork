{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression - Notebook Sample\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import pandas as pd\n",
    "# this line plots graphs in line\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the raw dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data set is containted in the same path, in the archive folder\n",
    "dataset = pd.read_csv(\"archive/creditcard.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Undersampling\n",
    "This is done due to the large bias in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rands(row):\n",
    "    if( row ==0):\n",
    "        return  np.random.uniform(low=0, high=0.999)\n",
    "    else:\n",
    "        return 0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "dataset['rand'] =dataset.Class.apply(rands)\n",
    "dataUnder = dataset.drop(dataset[(dataset.rand > 0.00167) ].index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataUnder=dataUnder.drop(['rand'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    492\n",
      "0    468\n",
      "Name: Class, dtype: int64\n",
      "as a percentage of the whole dataset\n",
      "1    51.25\n",
      "0    48.75\n",
      "Name: Class, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f2a85440cf8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "print(dataUnder.Class.value_counts())\n",
    "print(\"as a percentage of the whole dataset\")\n",
    "print((dataUnder.Class.value_counts()*100)/ len(dataUnder))\n",
    "dataUnder.Class.value_counts().plot(ax=ax, kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shuffeling the order of the data\n",
    "dataUnderShuffled = dataUnder.sample(frac =1, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataUnderShuffled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The time feature was removed since it was a feature relating the structre of the experiment. This feature represents the time elapsed since the start of the experiment, and has no relation to credit card fraud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataUnderShuffled=dataUnderShuffled.drop(['Time'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use of Corelation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimention Reduction\n",
    "Here we explore dimention reduction through the use of PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "Below are the functions created to be used by the Logistic Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sigmoid - returns a probability of the instance being in class 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sig_toGetProb(power):\n",
    "    return 1/(1+ np.exp(-power))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the partial derivative of the cross Entropy cost funtion wrt to wrt weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def ent_partial(X, Y,W,Bias, M):\n",
    "    \n",
    "    z = np.dot(W, X.T) + Bias\n",
    "\n",
    "    yPred= sig_toGetProb(z)\n",
    "  \n",
    "    dotSum = np.dot((Y - yPred), X)\n",
    "    minus1OnM = (-1 / M)\n",
    "    \n",
    "    biasDelta = minus1OnM * sum(Y - yPred)\n",
    "    weightDelta = minus1OnM *dotSum\n",
    "    return weightDelta, biasDelta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Decent - Used to minimise cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_decMACHINE(a, dataX, Y, W,B, iterations, M ):\n",
    "    # a -> the learning rate\n",
    "    # data -> containing a Class filed which is our Y. \n",
    "    # W starting wieghts\n",
    "    # interations -> how many iterations of gradient decent will be used.\n",
    "\n",
    "    # Performing Gradient Descent \n",
    "    for i in range(iterations):  \n",
    "        deltaW, deltaB = ent_partial(dataX, Y, W ,B ,M)\n",
    "        W = W - (a*deltaW)\n",
    "        B = B - (a*deltaB)\n",
    "\n",
    "    return W, B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prdictor(W,B,X):\n",
    "    z = np.dot(W, X.T) + B\n",
    "    \n",
    "    yPred= sig_toGetProb(z)\n",
    "\n",
    "    prediction = np.zeros(len(z))\n",
    "    for i in range(len(z)):\n",
    "        prediction[i] = (0 if sig_toGetProb(z[i])<0.5 else 1)\n",
    "    \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc(pred,act):\n",
    "    countCorrect = 0\n",
    "    for i in range(len(pred)):\n",
    "        if(int(pred[i]) ==int(act[i])):\n",
    "            countCorrect +=1\n",
    "    return countCorrect/ len(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "                   True class\n",
    "                   0        1\n",
    "            0    TN        FP\n",
    " Predicted  1    FN        TP\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_Matrix( pred, act):\n",
    "    confMat = np.zeros((2,2))\n",
    "    for i in range(len(pred)):\n",
    "        if(int(act[i]) == 0):\n",
    "            if(int(pred[i])==0):\n",
    "                confMat[0,0] +=1\n",
    "            elif (int(pred[i]) == 1):\n",
    "                confMat[1,0] += 1\n",
    "        if(int(act[i])==1):\n",
    "            if(int(pred[i]) == 0):\n",
    "                confMat[0,1] +=1\n",
    "            elif (int(pred[i]) == 1):\n",
    "                confMat[1,1] += 1\n",
    "    return confMat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rec_pre_f1_ac(conf):\n",
    "    TrueNeg = int(conf[0,0])\n",
    "    FalseNeg = int(conf[1,0])\n",
    "    FalsePos =int(conf[0,1])\n",
    "    TruePos = int(conf[1,1])\n",
    "    \n",
    "    recall = TruePos / (TruePos+ FalseNeg)\n",
    "    prec = TruePos/ (TruePos+ FalsePos)\n",
    "    f1 = 2 * (prec* recall)/ (prec+recall)\n",
    "    accuracy2 = (TruePos+ TrueNeg)/(FalseNeg+FalsePos+ TruePos+ TrueNeg)\n",
    "    \n",
    "    return recall, prec, f1, accuracy2\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Establishing a training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataUnderShuffled.to_numpy()\n",
    "Split = 0.75\n",
    "SplitPosition = int(len(data)*Split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train =  (720, 30)\n",
      "Shape of test =  (240, 30)\n"
     ]
    }
   ],
   "source": [
    "d_train= np.array(data[0:SplitPosition,:])\n",
    "d_test = np.array(data[SplitPosition:,:])\n",
    "print ('Shape of train = ',np.shape(d_train))\n",
    "print ('Shape of test = ',np.shape(d_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning - Establishing the right conditions for our model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameters like the learning rate and number of iterations need to be optimised for this task. To avoid introducing the unseen data (reserved for testing) in this tuning process, k fold cross validation is used.\n",
    "\n",
    "\n",
    "Here we make use of 5 folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "Split = 0.20\n",
    "SplitPosition = int(len(d_train)*Split)\n",
    "folds =[]\n",
    "data_to_split = d_train\n",
    "for i in range(5):\n",
    "    folds.append([data_to_split[SplitPosition*(i):(SplitPosition*(i+1)),:]][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(len(folds))\n",
    "#one_fold = folds[1]\n",
    "#print(one_fold.shape)\n",
    "#folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOLD NO : 0\n",
      "Fold  0 - accuracy :  0.8958333333333334\n",
      "FOLD NO : 1\n",
      "Fold  1 - accuracy :  0.9027777777777778\n",
      "FOLD NO : 2\n",
      "Fold  2 - accuracy :  0.9201388888888888\n",
      "FOLD NO : 3\n",
      "Fold  3 - accuracy :  0.9236111111111112\n",
      "FOLD NO : 4\n",
      "Fold  4 - accuracy :  0.9201388888888888\n",
      "Average over all folds :\n",
      "0.9125\n"
     ]
    }
   ],
   "source": [
    "iterations = 10000\n",
    "alpha  = 0.001\n",
    "np.random.seed(0)\n",
    "Wstart = np.random.rand(np.shape(currentData)[1] -1)/100\n",
    "B = 0.001\n",
    "# ----------------------------------------------------------------\n",
    "\n",
    "lst = [0,1,2,3,4]\n",
    "\n",
    "pool = cycle(lst)\n",
    "fold_results = []\n",
    "\n",
    "for i in range(5):\n",
    "    print(\"FOLD NO :\", i)\n",
    "    zero = next(pool)\n",
    "    one = next(pool)\n",
    "    two =next(pool)\n",
    "    three =next(pool)\n",
    "    four =next(pool)\n",
    "    next(pool)\n",
    "    \n",
    "    ######## creating train and val sets for this fold\n",
    "\n",
    "    train = np.concatenate((folds[zero], folds[one], folds[two]), axis=0,)\n",
    "    val  = np.concatenate((folds[three], folds[four]), axis=0,)\n",
    "\n",
    "    ##train\n",
    "    currentData = train\n",
    "    M = len(currentData)\n",
    "\n",
    "    Y = currentData[:, -1]\n",
    "    X = currentData[:,:-1]\n",
    "    Weights, Bias = grad_decMACHINE(alpha, X, Y, Wstart, B,iterations, M )\n",
    "    \n",
    "    ##predict \n",
    "    currentData = test\n",
    "\n",
    "    YTest = currentData[:, -1]\n",
    "    XTest = currentData[:,:-1]\n",
    "    preditcted = prdictor(Weights,Bias, XTest)\n",
    "    \n",
    "    \n",
    "    ##results    \n",
    "    accuraacy = acc(preditcted,YTest)\n",
    "    print(\"Fold \", i, \"- accuracy : \", accuraacy)\n",
    "    fold_results.append(accuraacy)\n",
    "\n",
    "\n",
    "    \n",
    "print(\"Average over all folds :\")\n",
    "print(np.mean(fold_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Now we train on the full train set, with the chosen hyper-params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "##train\n",
    "currentData = d_train\n",
    "M = len(currentData)\n",
    "\n",
    "Y = currentData[:, -1]\n",
    "X = currentData[:,:-1]\n",
    "Weights, Bias = grad_decMACHINE(alpha, X, Y, Wstart, B,iterations, M )\n",
    "\n",
    "##predict \n",
    "currentData = d_test\n",
    "\n",
    "YTest = currentData[:, -1]\n",
    "XTest = currentData[:,:-1]\n",
    "preditcted = prdictor(Weights,Bias, XTest)\n",
    "\n",
    "\n",
    "##results    \n",
    "confMat = confusion_Matrix(preditcted,YTest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall:     0.8759124087591241\n",
      "Precision:  0.9523809523809523\n",
      "F1:         0.9125475285171103\n",
      "accuracy:   0.9041666666666667\n"
     ]
    }
   ],
   "source": [
    "recall, precision, f1, accuracy = rec_pre_f1_ac(confMat)\n",
    "print(\"Recall:    \",recall)\n",
    "print(\"Precision: \",precision)\n",
    "print(\"F1:        \",f1)\n",
    "print(\"accuracy:  \",accuracy)\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selction by dropping lowest weights\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Weights</th>\n",
       "      <th>abs_w</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.185222</td>\n",
       "      <td>0.185222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.030285</td>\n",
       "      <td>0.030285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.284981</td>\n",
       "      <td>0.284981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.558859</td>\n",
       "      <td>0.558859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.307305</td>\n",
       "      <td>0.307305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.053582</td>\n",
       "      <td>0.053582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.123011</td>\n",
       "      <td>0.123011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.329393</td>\n",
       "      <td>0.329393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.185761</td>\n",
       "      <td>0.185761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.452636</td>\n",
       "      <td>0.452636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.231273</td>\n",
       "      <td>0.231273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.522885</td>\n",
       "      <td>0.522885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.080339</td>\n",
       "      <td>0.080339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.606049</td>\n",
       "      <td>0.606049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.000871</td>\n",
       "      <td>0.000871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.298983</td>\n",
       "      <td>0.298983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.427826</td>\n",
       "      <td>0.427826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.143271</td>\n",
       "      <td>0.143271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.112417</td>\n",
       "      <td>0.112417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.094724</td>\n",
       "      <td>0.094724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.150509</td>\n",
       "      <td>0.150509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.066035</td>\n",
       "      <td>0.066035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-0.171525</td>\n",
       "      <td>0.171525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-0.051662</td>\n",
       "      <td>0.051662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-0.045332</td>\n",
       "      <td>0.045332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-0.065711</td>\n",
       "      <td>0.065711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.122130</td>\n",
       "      <td>0.122130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-0.045427</td>\n",
       "      <td>0.045427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.002619</td>\n",
       "      <td>0.002619</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Weights     abs_w\n",
       "0  -0.185222  0.185222\n",
       "1   0.030285  0.030285\n",
       "2  -0.284981  0.284981\n",
       "3   0.558859  0.558859\n",
       "4  -0.307305  0.307305\n",
       "5   0.053582  0.053582\n",
       "6  -0.123011  0.123011\n",
       "7  -0.329393  0.329393\n",
       "8  -0.185761  0.185761\n",
       "9  -0.452636  0.452636\n",
       "10  0.231273  0.231273\n",
       "11 -0.522885  0.522885\n",
       "12 -0.080339  0.080339\n",
       "13 -0.606049  0.606049\n",
       "14  0.000871  0.000871\n",
       "15 -0.298983  0.298983\n",
       "16 -0.427826  0.427826\n",
       "17 -0.143271  0.143271\n",
       "18  0.112417  0.112417\n",
       "19 -0.094724  0.094724\n",
       "20  0.150509  0.150509\n",
       "21  0.066035  0.066035\n",
       "22 -0.171525  0.171525\n",
       "23 -0.051662  0.051662\n",
       "24 -0.045332  0.045332\n",
       "25 -0.065711  0.065711\n",
       "26  0.122130  0.122130\n",
       "27 -0.045427  0.045427\n",
       "28  0.002619  0.002619"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weightsDf = pd.DataFrame(Weights, columns=[\"Weights\"])\n",
    "weightsDf['abs_w'] = weightsDf.Weights.apply(abs)\n",
    "#weightsDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "weightsSorted = weightsDf.sort_values(by= [\"abs_w\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Weights</th>\n",
       "      <th>abs_w</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.000871</td>\n",
       "      <td>0.000871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.002619</td>\n",
       "      <td>0.002619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.030285</td>\n",
       "      <td>0.030285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-0.045332</td>\n",
       "      <td>0.045332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-0.045427</td>\n",
       "      <td>0.045427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-0.051662</td>\n",
       "      <td>0.051662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.053582</td>\n",
       "      <td>0.053582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-0.065711</td>\n",
       "      <td>0.065711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.066035</td>\n",
       "      <td>0.066035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.080339</td>\n",
       "      <td>0.080339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.094724</td>\n",
       "      <td>0.094724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.112417</td>\n",
       "      <td>0.112417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.122130</td>\n",
       "      <td>0.122130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.123011</td>\n",
       "      <td>0.123011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.143271</td>\n",
       "      <td>0.143271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.150509</td>\n",
       "      <td>0.150509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-0.171525</td>\n",
       "      <td>0.171525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.185222</td>\n",
       "      <td>0.185222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.185761</td>\n",
       "      <td>0.185761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.231273</td>\n",
       "      <td>0.231273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.284981</td>\n",
       "      <td>0.284981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.298983</td>\n",
       "      <td>0.298983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.307305</td>\n",
       "      <td>0.307305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.329393</td>\n",
       "      <td>0.329393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.427826</td>\n",
       "      <td>0.427826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.452636</td>\n",
       "      <td>0.452636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.522885</td>\n",
       "      <td>0.522885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.558859</td>\n",
       "      <td>0.558859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.606049</td>\n",
       "      <td>0.606049</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Weights     abs_w\n",
       "14  0.000871  0.000871\n",
       "28  0.002619  0.002619\n",
       "1   0.030285  0.030285\n",
       "24 -0.045332  0.045332\n",
       "27 -0.045427  0.045427\n",
       "23 -0.051662  0.051662\n",
       "5   0.053582  0.053582\n",
       "25 -0.065711  0.065711\n",
       "21  0.066035  0.066035\n",
       "12 -0.080339  0.080339\n",
       "19 -0.094724  0.094724\n",
       "18  0.112417  0.112417\n",
       "26  0.122130  0.122130\n",
       "6  -0.123011  0.123011\n",
       "17 -0.143271  0.143271\n",
       "20  0.150509  0.150509\n",
       "22 -0.171525  0.171525\n",
       "0  -0.185222  0.185222\n",
       "8  -0.185761  0.185761\n",
       "10  0.231273  0.231273\n",
       "2  -0.284981  0.284981\n",
       "15 -0.298983  0.298983\n",
       "4  -0.307305  0.307305\n",
       "7  -0.329393  0.329393\n",
       "16 -0.427826  0.427826\n",
       "9  -0.452636  0.452636\n",
       "11 -0.522885  0.522885\n",
       "3   0.558859  0.558859\n",
       "13 -0.606049  0.606049"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#weightsSorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#weightsSorted.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "wantedCols =weightsSorted.index.tolist()[-24:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here I am not doing validation properly. Just testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "##train\n",
    "currentData = d_train\n",
    "M = len(currentData)\n",
    "\n",
    "Y = currentData[:, -1]\n",
    "X = currentData[:,:-1]\n",
    "\n",
    "X = X[:,wantedCols]\n",
    "Wstart = Wstart[wantedCols]\n",
    "Weights, Bias = grad_decMACHINE(alpha, X, Y, Wstart, B,iterations, M )\n",
    "\n",
    "##predict \n",
    "currentData = d_test\n",
    "\n",
    "YTest = currentData[:, -1]\n",
    "XTest = currentData[:,:-1]\n",
    "XTest = XTest[:,wantedCols]\n",
    "preditcted = prdictor(Weights,Bias, XTest)\n",
    "\n",
    "\n",
    "##results    \n",
    "confMat = confusion_Matrix(preditcted,YTest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall:     0.9672131147540983\n",
      "Precision:  0.9365079365079365\n",
      "F1:         0.9516129032258064\n",
      "accuracy:   0.95\n"
     ]
    }
   ],
   "source": [
    "recall, precision, f1, accuracy = rec_pre_f1_ac(confMat)\n",
    "print(\"Recall:    \",recall)\n",
    "print(\"Precision: \",precision)\n",
    "print(\"F1:        \",f1)\n",
    "print(\"accuracy:  \",accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparision to 3rd Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression( solver= 'liblinear').fit(X, Y)\n",
    "pred =lr.predict(XTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall:     0.8759124087591241\n",
      "Precision:  0.9523809523809523\n",
      "F1:         0.9125475285171103\n",
      "accuracy:   0.9041666666666667\n"
     ]
    }
   ],
   "source": [
    "confMat = confusion_Matrix(preditcted,YTest)\n",
    "recall, precision, f1, accuracy = rec_pre_f1_ac(confMat)\n",
    "print(\"Recall:    \",recall)\n",
    "print(\"Precision: \",precision)\n",
    "print(\"F1:        \",f1)\n",
    "print(\"accuracy:  \",accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
